{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deebest-maker/ML-stock-forecasting-model/blob/main/stock_forecasting_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef1228aa",
      "metadata": {
        "id": "ef1228aa"
      },
      "source": [
        "# üìà Stock Market Forecasting Using LSTM & Random Forest  \n",
        "This project builds and compares two machine learning models to forecast stock market closing prices:\n",
        "- **LSTM Deep Learning Model**\n",
        "- **Random Forest Machine Learning Model**\n",
        "\n",
        "Both models will be trained on historical stock price data downloaded from Yahoo Finance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24cd5bb8",
      "metadata": {
        "id": "24cd5bb8"
      },
      "outputs": [],
      "source": [
        "# Install required libraries (run this cell in Colab; Colab already preinstalls most)\n",
        "!pip install yfinance scikit-learn tensorflow matplotlib -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec5435f",
      "metadata": {
        "id": "6ec5435f"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f8548ac",
      "metadata": {
        "id": "2f8548ac"
      },
      "outputs": [],
      "source": [
        "# Download stock data\n",
        "STOCK_TICKER = \"AAPL\"  # change to any ticker like \"TSLA\", \"GOOGL\", \"BTC-USD\"\n",
        "START_DATE = \"2015-01-01\"\n",
        "END_DATE = \"2024-12-31\"\n",
        "\n",
        "print(f\"üìä Downloading {STOCK_TICKER} data...\")\n",
        "data = yf.download(STOCK_TICKER, start=START_DATE, end=END_DATE)\n",
        "print(f\"‚úÖ Downloaded {len(data)} rows of price data\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51c7b8b",
      "metadata": {
        "id": "b51c7b8b"
      },
      "outputs": [],
      "source": [
        "# Display uploaded screenshot (for reference)\n",
        "from IPython.display import Image, display\n",
        "display(Image(\"/mnt/data/75ad14bb-a9fb-46e5-8256-835a32e862fe.png\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e8026c2",
      "metadata": {
        "id": "0e8026c2"
      },
      "outputs": [],
      "source": [
        "# Visualize closing prices\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(data['Close'], label='Close Price')\n",
        "plt.title(f'{STOCK_TICKER} Stock Price History')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price (USD)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6779095c",
      "metadata": {
        "id": "6779095c"
      },
      "outputs": [],
      "source": [
        "# Prepare training and testing data (80% train / 20% test)\n",
        "df = data[['Close']].dropna()\n",
        "split_index = int(len(df) * 0.8)\n",
        "train_data = df[:split_index]\n",
        "test_data = df[split_index:]\n",
        "print(\"Training samples:\", len(train_data))\n",
        "print(\"Testing samples:\", len(test_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5875ba9b",
      "metadata": {
        "id": "5875ba9b"
      },
      "outputs": [],
      "source": [
        "# LSTM model: prepare sequences, build, train, predict\n",
        "scaler_lstm = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler_lstm.fit_transform(df)\n",
        "\n",
        "scaled_train = scaled_data[:split_index]\n",
        "scaled_test = scaled_data[split_index:]\n",
        "\n",
        "def create_sequences(data, window=60):\n",
        "    X, y = [], []\n",
        "    for i in range(window, len(data)):\n",
        "        X.append(data[i-window:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "WINDOW = 60\n",
        "X_train_lstm, y_train_lstm = create_sequences(scaled_train, WINDOW)\n",
        "X_test_lstm, y_test_lstm = create_sequences(scaled_test, WINDOW)\n",
        "\n",
        "X_train_lstm = X_train_lstm.reshape(-1, WINDOW, 1)\n",
        "X_test_lstm = X_test_lstm.reshape(-1, WINDOW, 1)\n",
        "\n",
        "model_lstm = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(WINDOW,1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model (reduce epochs if you're running on limited runtime)\n",
        "history = model_lstm.fit(\n",
        "    X_train_lstm, y_train_lstm,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "pred_lstm = model_lstm.predict(X_test_lstm)\n",
        "pred_lstm = scaler_lstm.inverse_transform(pred_lstm)\n",
        "y_actual_lstm = scaler_lstm.inverse_transform(y_test_lstm.reshape(-1,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c31920f3",
      "metadata": {
        "id": "c31920f3"
      },
      "outputs": [],
      "source": [
        "# LSTM evaluation metrics\n",
        "mae_lstm = mean_absolute_error(y_actual_lstm, pred_lstm)\n",
        "rmse_lstm = np.sqrt(mean_squared_error(y_actual_lstm, pred_lstm))\n",
        "r2_lstm = r2_score(y_actual_lstm, pred_lstm)\n",
        "\n",
        "print(\"üìä LSTM Metrics:\")\n",
        "print(f\"MAE: {mae_lstm:.4f}\")\n",
        "print(f\"RMSE: {rmse_lstm:.4f}\")\n",
        "print(f\"R2: {r2_lstm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd09929",
      "metadata": {
        "id": "6fd09929"
      },
      "outputs": [],
      "source": [
        "# Random Forest: feature engineering, train, predict\n",
        "def create_features(df, window=60):\n",
        "    df2 = df.copy()\n",
        "    for i in range(1, window+1):\n",
        "        df2[f'lag_{i}'] = df2['Close'].shift(i)\n",
        "    df2['roll_mean_7'] = df2['Close'].rolling(7).mean()\n",
        "    df2['roll_std_7'] = df2['Close'].rolling(7).std()\n",
        "    df2['roll_mean_30'] = df2['Close'].rolling(30).mean()\n",
        "    df2['roll_std_30'] = df2['Close'].rolling(30).std()\n",
        "    return df2.dropna()\n",
        "\n",
        "df_rf = create_features(df)\n",
        "split_rf = int(len(df_rf) * 0.8)\n",
        "\n",
        "X_train_rf = df_rf.iloc[:split_rf, 1:]\n",
        "y_train_rf = df_rf.iloc[:split_rf, 0]\n",
        "X_test_rf = df_rf.iloc[split_rf:, 1:]\n",
        "y_test_rf = df_rf.iloc[split_rf:, 0]\n",
        "\n",
        "model_rf = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_rf.fit(X_train_rf, y_train_rf)\n",
        "pred_rf = model_rf.predict(X_test_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f27886e",
      "metadata": {
        "id": "6f27886e"
      },
      "outputs": [],
      "source": [
        "# Random Forest evaluation metrics\n",
        "mae_rf = mean_absolute_error(y_test_rf, pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test_rf, pred_rf))\n",
        "r2_rf = r2_score(y_test_rf, pred_rf)\n",
        "\n",
        "print(\"üìä Random Forest Metrics:\")\n",
        "print(f\"MAE: {mae_rf:.4f}\")\n",
        "print(f\"RMSE: {rmse_rf:.4f}\")\n",
        "print(f\"R2: {r2_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2030f631",
      "metadata": {
        "id": "2030f631"
      },
      "outputs": [],
      "source": [
        "# Compare models\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"LSTM\", \"Random Forest\"],\n",
        "    \"MAE\": [mae_lstm, mae_rf],\n",
        "    \"RMSE\": [rmse_lstm, rmse_rf],\n",
        "    \"R2\": [r2_lstm, r2_rf]\n",
        "})\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518022e9",
      "metadata": {
        "id": "518022e9"
      },
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(y_actual_lstm, label=\"Actual\")\n",
        "plt.plot(pred_lstm, label=\"LSTM Predicted\")\n",
        "plt.title(\"LSTM Forecast\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(y_test_rf.values, label=\"Actual\")\n",
        "plt.plot(pred_rf, label=\"Random Forest Predicted\")\n",
        "plt.title(\"Random Forest Forecast\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07894ee",
      "metadata": {
        "id": "e07894ee"
      },
      "outputs": [],
      "source": [
        "# Error analysis (histograms)\n",
        "fig, axes = plt.subplots(1,2, figsize=(14,4))\n",
        "axes[0].hist((y_actual_lstm.flatten() - pred_lstm.flatten()), bins=50, color='red', alpha=0.6)\n",
        "axes[0].set_title('LSTM Errors')\n",
        "axes[1].hist((y_test_rf.values - pred_rf), bins=50, color='green', alpha=0.6)\n",
        "axes[1].set_title('Random Forest Errors')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166cbadb",
      "metadata": {
        "id": "166cbadb"
      },
      "outputs": [],
      "source": [
        "# Future prediction for next N days\n",
        "N_DAYS = 30  # change this to forecast more/less days\n",
        "\n",
        "# LSTM iterative forecasting using last WINDOW days\n",
        "last_window = scaled_data[-WINDOW:].reshape(1, WINDOW, 1).copy()\n",
        "lstm_forecast_scaled = []\n",
        "input_seq = last_window.copy()\n",
        "for _ in range(N_DAYS):\n",
        "    pred_scaled = model_lstm.predict(input_seq)[0,0]\n",
        "    lstm_forecast_scaled.append(pred_scaled)\n",
        "    # append and slide window\n",
        "    new_seq = np.append(input_seq.flatten()[1:], pred_scaled).reshape(1, WINDOW, 1)\n",
        "    input_seq = new_seq\n",
        "\n",
        "lstm_forecast = scaler_lstm.inverse_transform(np.array(lstm_forecast_scaled).reshape(-1,1)).flatten()\n",
        "\n",
        "# Random Forest future forecast using last available features\n",
        "# We'll build features iteratively using predicted prices for lags and rolling stats (simple approach)\n",
        "future_rf_preds = []\n",
        "df_recent = df_rf.copy()\n",
        "for i in range(N_DAYS):\n",
        "    last_row = df_recent.iloc[-1].copy()\n",
        "    # build feature vector for prediction (lags shift by 1, newest lag_1 is last close or last predicted)\n",
        "    features = []\n",
        "    # use the last close from original df or last predicted value\n",
        "    current_close = df_recent['Close'].iloc[-1]\n",
        "    # create new lag values: lag_1 becomes current_close, lag_2 becomes previous lag_1, ...\n",
        "    for j in range(1, 61):\n",
        "        if j == 1:\n",
        "            features.append(current_close)\n",
        "        else:\n",
        "            features.append(df_recent[f'lag_{j-1}'].iloc[-1])\n",
        "    # rolling stats (use last values; not updated for predicted series for simplicity)\n",
        "    features.append(df_recent['roll_mean_7'].iloc[-1])\n",
        "    features.append(df_recent['roll_std_7'].iloc[-1])\n",
        "    features.append(df_recent['roll_mean_30'].iloc[-1])\n",
        "    features.append(df_recent['roll_std_30'].iloc[-1])\n",
        "    features = np.array(features).reshape(1,-1)\n",
        "    pred = model_rf.predict(features)[0]\n",
        "    future_rf_preds.append(pred)\n",
        "    # append a new row to df_recent with predicted close and shift lags\n",
        "    new_row = df_recent.iloc[-1].copy()\n",
        "    new_row['Close'] = pred\n",
        "    # update lags\n",
        "    for j in range(60,0,-1):\n",
        "        if j==1:\n",
        "            new_row['lag_1'] = current_close\n",
        "        else:\n",
        "            new_row[f'lag_{j}'] = df_recent[f'lag_{j-1}'].iloc[-1]\n",
        "    # update rolling stats simplistically by appending pred to a temp series\n",
        "    temp_close_series = list(df_recent['Close'].values[-29:]) + [pred]\n",
        "    new_row['roll_mean_7'] = np.mean(temp_close_series[-7:])\n",
        "    new_row['roll_std_7'] = np.std(temp_close_series[-7:])\n",
        "    new_row['roll_mean_30'] = np.mean(temp_close_series[-30:]) if len(temp_close_series)>=30 else np.mean(temp_close_series)\n",
        "    new_row['roll_std_30'] = np.std(temp_close_series[-30:]) if len(temp_close_series)>=30 else np.std(temp_close_series)\n",
        "    df_recent = df_recent.append(new_row, ignore_index=True)\n",
        "\n",
        "# Prepare date index for forecast starting after last date in df\n",
        "last_date = df.index[-1]\n",
        "forecast_dates = pd.bdate_range(start=last_date + pd.Timedelta(days=1), periods=N_DAYS)\n",
        "\n",
        "future_df = pd.DataFrame({\n",
        "    'date': forecast_dates,\n",
        "    'lstm_forecast': lstm_forecast,\n",
        "    'rf_forecast': future_rf_preds\n",
        "})\n",
        "future_df.set_index('date', inplace=True)\n",
        "future_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6199d3df",
      "metadata": {
        "id": "6199d3df"
      },
      "outputs": [],
      "source": [
        "# Plot future forecasts along with last 200 days of actuals\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(df['Close'][-200:], label='Actual (last 200 days)')\n",
        "plt.plot(future_df['lstm_forecast'], label='LSTM Forecast (next days)', linestyle='--')\n",
        "plt.plot(future_df['rf_forecast'], label='RF Forecast (next days)', linestyle='--')\n",
        "plt.title(f'Future Forecasts for {STOCK_TICKER}')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe843a9",
      "metadata": {
        "id": "cfe843a9"
      },
      "outputs": [],
      "source": [
        "# Save trained models to files (in Colab these will be in /content)\n",
        "model_lstm.save('lstm_model.h5')\n",
        "\n",
        "import pickle\n",
        "with open('rf_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_rf, f)\n",
        "\n",
        "print('Saved lstm_model.h5 and rf_model.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98b1e6a",
      "metadata": {
        "id": "b98b1e6a"
      },
      "source": [
        "# üèÅ Project Complete\n",
        "\n",
        "You have:\n",
        "- Trained an LSTM model and a Random Forest model.\n",
        "- Compared their performance.\n",
        "- Generated a 30-day future forecast from both models (iterative LSTM and iterative RF approximation).\n",
        "- Saved the trained models.\n",
        "\n",
        "**To export this notebook to PDF**: use `File ‚Üí Print` and choose \"Save as PDF\" (best for Colab).\n",
        "**To run locally**: download the `.ipynb` and run in Jupyter or Colab.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}